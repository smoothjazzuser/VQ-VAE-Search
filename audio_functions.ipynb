{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc,roc_auc_score,precision_recall_curve,average_precision_score,f1_score,precision_score,recall_score\n",
    "import scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import transformers as ppb\n",
    "import huggingface_hub as hf_hub\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup, AutoModel\n",
    "import imageio\n",
    "from time import sleep\n",
    "import timeit\n",
    "import cv2\n",
    "import shutil\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download audio dataset\n",
    "if not os.path.exists('./ESC-50-master'):\n",
    "    if not os.path.exists('./master'):\n",
    "        !wget https://codeload.github.com/karolpiczak/ESC-50/zip/refs/heads/master\n",
    "    !unzip master\n",
    "    if os.path.exists('./master'):\n",
    "        !rm master\n",
    "\n",
    "# collect a list of audio files\n",
    "audio_files = glob.glob('./ESC-50-master/audio/*.wav')\n",
    "\n",
    "# divide audiofiles into train and test\n",
    "train_files, test_files = train_test_split(audio_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# view folder structure and filenames\n",
    "#!ls -l ESC-50-master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# view metadata \n",
    "#!cat ESC-50-master/meta/esc50.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_search:\n",
    "    def __init__(self):\n",
    "        self.audio_files = glob.glob('./ESC-50-master/audio/*.wav')\n",
    "        self.train_files, self.test_files = train_test_split(audio_files, test_size=0.2, random_state=42)\n",
    "        self.df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "        # find sample rate of files\n",
    "        self.sr = librosa.get_samplerate(self.audio_files[0])\n",
    "\n",
    "    # convert audio to spectrogram \n",
    "    def to_spectrogram(self, audio_file, win=50, hop_length=100, n_fft=2000, log=True, RGB=False):\n",
    "        if type(audio_file) == str:\n",
    "            y, self.sr = librosa.load(audio_file)\n",
    "            X = S = librosa.feature.melspectrogram(y=y, sr=self.sr, window=win, n_fft=n_fft, hop_length=hop_length)\n",
    "            if RGB == False:\n",
    "                if log: S = X = librosa.power_to_db(X, ref=np.max)\n",
    "\n",
    "            if RGB:\n",
    "\n",
    "                Y = librosa.power_to_db(X, ref=np.max)\n",
    "                Z = librosa.feature.melspectrogram(y=y, sr=self.sr, window=200, n_fft=n_fft, hop_length=hop_length)\n",
    "                S = np.dstack((X, Y, Z))\n",
    "            return S\n",
    "        else:\n",
    "            S = librosa.feature.melspectrogram(y=audio_file, sr=self.sr, hop_length=hop_length, n_fft=n_fft, win_length=win)\n",
    "            if log: S = librosa.power_to_db(S, ref=np.max)\n",
    "            return S\n",
    "    \n",
    "    def from_spectrogram(self, spectrogram,  hop_length=100, n_fft=2048, win=scipy.signal.hann):\n",
    "        # undo power_to_db\n",
    "        #S = librosa.db_to_power(spectrogram, ref=np.max)\n",
    "        return librosa.feature.inverse.mel_to_audio(spectrogram, sr=self.sr, n_fft=n_fft, hop_length=hop_length, window=win)\n",
    "\n",
    "    def to_mfcc(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        return mfccs\n",
    "\n",
    "    def from_mfcc(self, mfccs):\n",
    "        return librosa.feature.inverse.mfcc_to_audio(mfccs)\n",
    "\n",
    "    def to_fourier(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        fourier = np.fft.fft(y)\n",
    "        return fourier\n",
    "\n",
    "    def from_fourier(self, fourier):\n",
    "        return np.fft.ifft(fourier)\n",
    "\n",
    "    def spectrogam2d_to_fourier(self, spectrogram):\n",
    "        return np.fft.fft(spectrogram)\n",
    "\n",
    "    def spectrogram2d_from_fourier(self, fourier):\n",
    "        return np.fft.ifft(fourier)\n",
    "\n",
    "    def to_wavelet(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        wavelet = scipy.signal.cwt(y, scipy.signal.ricker, np.arange(1, 101))\n",
    "        return wavelet\n",
    "\n",
    "    def from_wavelet(self, wavelet):\n",
    "        return scipy.signal.icwt(wavelet, scipy.signal.ricker, np.arange(1, 101))\n",
    "\n",
    "    def to_wavelet_2d(self, spectrogram):\n",
    "        wavelet = scipy.signal.cwt(spectrogram, scipy.signal.ricker, np.arange(1, 101))\n",
    "        return wavelet\n",
    "\n",
    "    def from_wavelet_2d(self, wavelet):\n",
    "        return scipy.signal.icwt(wavelet, scipy.signal.ricker, np.arange(1, 101))\n",
    "\n",
    "    def play_audio(self, audio_file):\n",
    "        if type(audio_file) == str:\n",
    "            return ipd.Audio(audio_file,  rate=self.sr)\n",
    "        else:\n",
    "            return ipd.Audio(audio_file, rate=self.sr)\n",
    "\n",
    "    def visualize_spectrogram(self, audio_file):\n",
    "        if type(audio_file) == str:\n",
    "            log_S = self.to_spectrogram(audio_file)\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            librosa.display.specshow(log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "            plt.title('mel power spectrogram ')\n",
    "            plt.colorbar(format='%+02.0f dB')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            librosa.display.specshow(audio_file, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "            plt.title('mel power spectrogram ')\n",
    "            plt.colorbar(format='%+02.0f dB')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def visualize_mfcc(self, audio_file):\n",
    "        mfccs = self.to_mfcc(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(mfccs, sr=self.sr, x_axis='time')\n",
    "        plt.colorbar()\n",
    "        plt.title('MFCC')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_fourier(self, audio_file):\n",
    "        fourier = self.to_fourier(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_wavelet(self, audio_file):\n",
    "        wavelet = self.to_wavelet(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Wavelet')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_wavelet_2d(self, audio_file):\n",
    "        wavelet = self.to_wavelet_2d(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Wavelet 2D')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(spectrogram)\n",
    "        plt.title('Spectrogram 2D')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_fourier(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        fourier = self.spectrogam2d_to_fourier(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Spectrogram 2D Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_wavelet(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        wavelet = self.to_wavelet_2d(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Spectrogram 2D Wavelet')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_mfcc(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        mfcc = self.to_mfcc(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(mfcc)\n",
    "        plt.title('Spectrogram 2D MFCC')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_mfcc_fourier(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        mfcc = self.to_mfcc(spectrogram)\n",
    "        fourier = self.spectrogam2d_to_fourier(mfcc)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Spectrogram 2D MFCC Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def return_shape_of_audio(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        return y.shape\n",
    "\n",
    "    def return_shape_of_spectrogram(self, audio_file):\n",
    "        log_S = self.to_spectrogram(audio_file)\n",
    "        return log_S.shape\n",
    "\n",
    "    def return_shape_of_mfcc(self, audio_file):\n",
    "        mfccs = self.to_mfcc(audio_file)\n",
    "        return mfccs.shape\n",
    "\n",
    "    def return_shape_of_fourier(self, audio_file):\n",
    "        fourier = self.to_fourier(audio_file)\n",
    "        return fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test audio_search class\n",
    "search = audio_search()\n",
    "search.visualize_spectrogram('./ESC-50-master/audio/1-137-A-32.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft, hop_length=2000, 150\n",
    "win=np.hanning(n_fft)\n",
    "win = 50\n",
    "spec = search.to_spectrogram('./ESC-50-master/audio/1-137-A-32.wav', n_fft=n_fft, hop_length=hop_length, win=win, log=False)\n",
    "aud = search.from_spectrogram(spec, n_fft=n_fft, hop_length=hop_length, win=win)\n",
    "#aud = aud / np.max(np.abs(aud)) * 32767\n",
    "#play audio\n",
    "\n",
    "search.play_audio(aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if os.path.exists('./ESC-50-master/mel_spectrograms'):\n",
    " #   shutil.rmtree('./ESC-50-master/mel_spectrograms')\n",
    "\n",
    "if not os.path.exists('./ESC-50-master/mel_spectrograms'):\n",
    "    os.makedirs('./ESC-50-master/mel_spectrograms')\n",
    "\n",
    "num_files = len(os.listdir('./ESC-50-master/audio'))\n",
    "file_names = glob.glob('./ESC-50-master/audio/*.wav')\n",
    "\n",
    "win=np.hanning(n_fft)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "def process_files(wav_path, n_fft, hop_length, win, log, RGB = False):\n",
    "    img = search.to_spectrogram(wav_path, n_fft=n_fft, hop_length=hop_length, win=win, log=True, RGB=RGB)\n",
    "    if RGB == False: \n",
    "        img = img.reshape(img.shape[0], img.shape[1], 1)\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img)) * 255\n",
    "    else:\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img)) * 255\n",
    "\n",
    "    \n",
    "    img_name = wav_path.split('/')[-1].split('.')[0]\n",
    "    img_path = './ESC-50-master/mel_spectrograms/' + img_name + '.png'\n",
    "    cv2.imwrite(img_path, img, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "\n",
    "#paralel using joblib\n",
    "Parallel(n_jobs=4, backend='multiprocessing')(delayed(process_files)(wav_path, n_fft=n_fft, hop_length=hop_length, win=win, log=True, RGB=False) for wav_path in file_names)\n",
    "  \n",
    "end = timeit.default_timer()\n",
    "print(end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperperameters for fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# VAE from huggingface transfomers https://huggingface.co/Fraser/transformer-vae\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, model_name, device, latent_dim=128, max_seq_length=512):\n",
    "        super(VAE, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2 * latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.model.config.hidden_size),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)[0]\n",
    "        x = x[:, 0, :]\n",
    "        mu_logvar = self.encode(x).view(-1, 2, self.latent_dim)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n",
    "\n",
    "    def train(self, train_loader, optimizer, epoch):\n",
    "        self.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = self(data)\n",
    "            loss = self.loss_function(recon_batch, data, mu , logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(data)))\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(    \n",
    "            epoch, train_loss / len(train_loader.dataset)))\n",
    "    \n",
    "    def generate(self, n=1):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(n, self.latent_dim).to(self.device)\n",
    "            samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "# create dataloader for VAE using audio_search() class\n",
    "train_loader = torch.utils.data.DataLoader('./VQ-VAE-Search/ESC-50-master/mel_spectrograms/', batch_size=1, shuffle=True)\n",
    "\n",
    "# hyperperameters for VAE\n",
    "model_name = 'Fraser/transformer-vae'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_dim = 128\n",
    "max_seq_length = 512\n",
    "\n",
    "# create VAE model\n",
    "model = VAE(model_name, device, latent_dim, max_seq_length)\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# train VAE\n",
    "for epoch in range(1, 10):\n",
    "    model.train(train_loader, optimizer, epoch)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a25effbdb37c891a2e9d4084264472a304386d1b4f4a3dd9d5e57807f471f70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
