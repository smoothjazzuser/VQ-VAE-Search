{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc,roc_auc_score,precision_recall_curve,average_precision_score,f1_score,precision_score,recall_score\n",
    "import scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import transformers as ppb\n",
    "import huggingface_hub as hf_hub\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download audio dataset\n",
    "if not os.path.exists('./ESC-50-master'):\n",
    "    if not os.path.exists('./ESC-50-master.zip'):\n",
    "        !wget https://codeload.github.com/karolpiczak/ESC-50/zip/refs/heads/master\n",
    "    !unzip ESC-50-master.zip\n",
    "    if os.path.exists('./ESC-50-master.zip'):\n",
    "        !rm ESC-50-master.zip\n",
    "\n",
    "# collect a list of audio files\n",
    "audio_files = glob.glob('./ESC-50-master/audio/*.wav')\n",
    "\n",
    "# divide audiofiles into train and test\n",
    "train_files, test_files = train_test_split(audio_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# view folder structure and filenames\n",
    "!ls -l ESC-50-master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# view metadata \n",
    "!cat ESC-50-master/meta/esc50.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_search:\n",
    "    def __init__(self):\n",
    "        self.audio_files = glob.glob('./ESC-50-master/audio/*.wav')\n",
    "        self.train_files, self.test_files = train_test_split(audio_files, test_size=0.2, random_state=42)\n",
    "        self.df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "        # find sample rate of files\n",
    "        self.sr = librosa.get_samplerate(self.audio_files[0])\n",
    "\n",
    "    # convert audio to spectrogram \n",
    "    def to_spectrogram(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "        return log_S\n",
    "    \n",
    "    def from_spectrogram(self, spectrogram):\n",
    "        return librosa.feature.inverse.mel_to_audio(spectrogram)\n",
    "\n",
    "    def to_mfcc(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        return mfccs\n",
    "\n",
    "    def from_mfcc(self, mfccs):\n",
    "        return librosa.feature.inverse.mfcc_to_audio(mfccs)\n",
    "\n",
    "    def to_fourier(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        fourier = np.fft.fft(y)\n",
    "        return fourier\n",
    "\n",
    "    def from_fourier(self, fourier):\n",
    "        return np.fft.ifft(fourier)\n",
    "\n",
    "    def spectrogam2d_to_fourier(self, spectrogram):\n",
    "        return np.fft.fft(spectrogram)\n",
    "\n",
    "    def spectrogram2d_from_fourier(self, fourier):\n",
    "        return np.fft.ifft(fourier)\n",
    "\n",
    "    def to_wavelet(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        wavelet = scipy.signal.cwt(y, scipy.signal.ricker, np.arange(1, 101))\n",
    "        return wavelet\n",
    "\n",
    "    def from_wavelet(self, wavelet):\n",
    "        return scipy.signal.icwt(wavelet, scipy.signal.ricker, np.arange(1, 101))\n",
    "\n",
    "    def to_wavelet_2d(self, spectrogram):\n",
    "        wavelet = scipy.signal.cwt(spectrogram, scipy.signal.ricker, np.arange(1, 101))\n",
    "        return wavelet\n",
    "\n",
    "    def from_wavelet_2d(self, wavelet):\n",
    "        return scipy.signal.icwt(wavelet, scipy.signal.ricker, np.arange(1, 101))\n",
    "\n",
    "    def play_audio(self, audio_file):\n",
    "        return ipd.Audio(audio_file)\n",
    "\n",
    "    def visualize_spectrogram(self, audio_file):\n",
    "        log_S = self.to_spectrogram(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title('mel power spectrogram ')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_mfcc(self, audio_file):\n",
    "        mfccs = self.to_mfcc(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(mfccs, sr=self.sr, x_axis='time')\n",
    "        plt.colorbar()\n",
    "        plt.title('MFCC')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_fourier(self, audio_file):\n",
    "        fourier = self.to_fourier(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_wavelet(self, audio_file):\n",
    "        wavelet = self.to_wavelet(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Wavelet')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_wavelet_2d(self, audio_file):\n",
    "        wavelet = self.to_wavelet_2d(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Wavelet 2D')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(spectrogram)\n",
    "        plt.title('Spectrogram 2D')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_fourier(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        fourier = self.spectrogam2d_to_fourier(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Spectrogram 2D Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_wavelet(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        wavelet = self.to_wavelet_2d(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(wavelet)\n",
    "        plt.title('Spectrogram 2D Wavelet')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_mfcc(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        mfcc = self.to_mfcc(spectrogram)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(mfcc)\n",
    "        plt.title('Spectrogram 2D MFCC')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_spectrogram2d_mfcc_fourier(self, audio_file):\n",
    "        spectrogram = self.to_spectrogram(audio_file)\n",
    "        mfcc = self.to_mfcc(spectrogram)\n",
    "        fourier = self.spectrogam2d_to_fourier(mfcc)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(fourier)\n",
    "        plt.title('Spectrogram 2D MFCC Fourier')\n",
    "        plt.show()\n",
    "\n",
    "    def return_shape_of_audio(self, audio_file):\n",
    "        y, sr = librosa.load(audio_file)\n",
    "        return y.shape\n",
    "\n",
    "    def return_shape_of_spectrogram(self, audio_file):\n",
    "        log_S = self.to_spectrogram(audio_file)\n",
    "        return log_S.shape\n",
    "\n",
    "    def return_shape_of_mfcc(self, audio_file):\n",
    "        mfccs = self.to_mfcc(audio_file)\n",
    "        return mfccs.shape\n",
    "\n",
    "    def return_shape_of_fourier(self, audio_file):\n",
    "        fourier = self.to_fourier(audio_file)\n",
    "        return fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test audio_search class\n",
    "search = audio_search()\n",
    "search.visualize_spectrogram('./ESC-50-master/audio/1-137-A-32.wav')\n",
    "search.visualize_spectrogram2d_fourier('./ESC-50-master/audio/1-137-A-32.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperperameters for fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# VAE from huggingface transfomers https://huggingface.co/Fraser/transformer-vae\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, model_name, device, latent_dim=128, max_seq_length=512):\n",
    "        super(VAE, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.model.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2 * latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.model.config.hidden_size),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)[0]\n",
    "        x = x[:, 0, :]\n",
    "        mu_logvar = self.encode(x).view(-1, 2, self.latent_dim)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n",
    "\n",
    "    def train(self, train_loader, optimizer, epoch):\n",
    "        self.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = self(data)\n",
    "            loss = self.loss_function(recon_batch, data, mu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a25effbdb37c891a2e9d4084264472a304386d1b4f4a3dd9d5e57807f471f70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
