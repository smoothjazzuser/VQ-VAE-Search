{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omv8PhrnmPmG"
      },
      "outputs": [],
      "source": [
        "class VectorQuantizer(torch.nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
        "        super(VectorQuantizer, self).__init__()\n",
        "        \n",
        "        self._embedding_dim = embedding_dim\n",
        "        self._num_embeddings = num_embeddings\n",
        "        \n",
        "        self._embedding = torch.nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
        "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
        "        self._commitment_cost = commitment_cost\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # convert inputs from BCHW -> BHWC\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        input_shape = inputs.shape\n",
        "        \n",
        "        # Flatten input\n",
        "        flat_input = inputs.view(-1, self._embedding_dim)\n",
        "        \n",
        "        # Calculate distances\n",
        "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
        "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
        "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
        "            \n",
        "        # Encoding\n",
        "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
        "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
        "        encodings.scatter_(1, encoding_indices, 1)\n",
        "        \n",
        "        # Quantize and unflatten\n",
        "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
        "        \n",
        "        # Loss\n",
        "        e_latent_loss = torch.nn.functional.mse_loss(quantized.detach(), inputs)\n",
        "        q_latent_loss = torch.nn.functional.mse_loss(quantized, inputs.detach())\n",
        "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
        "        \n",
        "        quantized = inputs + (quantized - inputs).detach()\n",
        "        avg_probs = torch.mean(encodings, dim=0)\n",
        "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
        "        \n",
        "        # convert quantized from BHWC -> BCHW\n",
        "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQsosddb1NyX"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim):\n",
        "    super().__init__()\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(n_input_channels, hidden_size, kernel_size=3, stride=2, padding=1),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, hidden_size, kernel_size=3),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, 2*hidden_size, kernel_size=3),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(2*hidden_size, 2*hidden_size, kernel_size=3, stride=2),\n",
        "        torch.nn.GELU(),\n",
        "        #torch.nn.Flatten()\n",
        "    )\n",
        "\n",
        "    #self.linear_mean = torch.nn.Linear(2*hidden_size*25, latent_dim)\n",
        "    #self.linear_logvar = torch.nn.Linear(2*hidden_size*25, latent_dim)\n",
        "    #self.linear = torch.nn.Linear(2*hidden_size*16, latent_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    #x = self.linear(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEJJPsXK6UbO"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim):\n",
        "    super().__init__()\n",
        "    #self.linear = torch.nn.Sequential(torch.nn.Linear(latent_dim, 2 * 16 * hidden_size), torch.nn.GELU())\n",
        "\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.ConvTranspose2d(2*hidden_size, 2*hidden_size, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(2*hidden_size, 2*hidden_size, kernel_size=3, padding=1),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.ConvTranspose2d(2*hidden_size, hidden_size, kernel_size=3, stride=2, output_padding=1, padding=1), \n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, hidden_size, kernel_size=3), # , padding=1\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.ConvTranspose2d(hidden_size, n_input_channels, kernel_size=3, stride=2, output_padding=1, padding=1), \n",
        "        torch.nn.Tanh(),\n",
        "        #torch.nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    #x = self.linear(x)\n",
        "    #x = x.reshape(x.shape[0], -1, 4, 4)\n",
        "    x = self.model(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiaPnvn9A_jZ"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim, num_embeddings, embedding_dim, commitment_cost):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(n_input_channels, hidden_size, latent_dim)\n",
        "    self.decoder = Decoder(n_input_channels, hidden_size, latent_dim)\n",
        "    self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    loss, quantized, perplexity, enc = self._vq_vae(x)\n",
        "    x = self.decoder(quantized)\n",
        "    return x, enc, loss, perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Xxbj7UGFQC"
      },
      "outputs": [],
      "source": [
        "def visualize_grid(x_batch):\n",
        "  im_rec = Image.fromarray(torchvision.utils.make_grid((x_batch*0.5+0.5) * 255).permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "  #im_rec = Image.fromarray(torchvision.utils.make_grid((x_batch) * 255).permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "  return im_rec.resize((im_rec.size[0]*4, im_rec.size[1]*4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkU_V8b2BpRB"
      },
      "outputs": [],
      "source": [
        "n_input_channels, hidden_size, latent_dim = 1, 28, 16\n",
        "num_embeddings, embedding_dim, commitment_cost = 128, 56, 0.25 # embedding_dim = num_channels at the output of the encoder\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Autoencoder(n_input_channels, hidden_size, latent_dim, num_embeddings, embedding_dim, commitment_cost).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jSbPO8E04on",
        "outputId": "ad243f5a-5e8e-4cb3-e703-9fc3827ca002"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))\n",
        "     ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6sq3KSsqjhU"
      },
      "outputs": [],
      "source": [
        "data_variance = torch.var(trainset.data / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22QYoamrC28c",
        "outputId": "ada18949-9e0b-454f-b412-cd03c2db808b"
      },
      "outputs": [],
      "source": [
        "for epoch in range(7):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        x, labels = data\n",
        "        x = x.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, enc, vq_loss, perplexity = model(x)\n",
        "        mse_loss = torch.nn.functional.mse_loss(x, x_hat) / data_variance\n",
        "        #mse_loss = mse_loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
        "        #bce_loss = torch.nn.functional.binary_cross_entropy(x_hat.view(-1, 1024), x.view(-1, 1024), reduction='sum')\n",
        "        #loss = bce_loss + kl_loss \n",
        "        loss = mse_loss + vq_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % batch_size * 5 == batch_size * 5 - 5:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (batch_size * 5):.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    if (epoch + 1) % 3 == 0:\n",
        "      for g in optimizer.param_groups:\n",
        "        learning_rate *= 0.1\n",
        "        g['lr'] = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxU0kJxyFemS"
      },
      "outputs": [],
      "source": [
        "for data in testloader:\n",
        "  x, labels = data\n",
        "  x = x.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x_hat = model(x)[0]\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bpO7JxA1mDyd",
        "outputId": "49ba56e6-bc66-478f-fe2e-6bceb144875d"
      },
      "outputs": [],
      "source": [
        "visualize_grid(x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "suxcg6W0H3ul",
        "outputId": "c5d5df74-762b-4c81-9fb6-bc274123c233"
      },
      "outputs": [],
      "source": [
        "visualize_grid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk2CiYbhtU_e"
      },
      "outputs": [],
      "source": [
        "means, lbls = [], []\n",
        "for data in testloader:\n",
        "  x, labels = data\n",
        "  x = x.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x_mean = model.encoder(x)[0]\n",
        "  means.append(x_mean)\n",
        "  lbls.append(labels)\n",
        "\n",
        "features = torch.cat(means,0)\n",
        "features = features.detach().cpu().numpy()\n",
        "\n",
        "nsamples, nx, ny = features.shape\n",
        "features = features.reshape((nsamples,nx*ny))\n",
        "\n",
        "labels = torch.cat(lbls).numpy()\n",
        "\n",
        "print(features.shape, labels.shape)\n",
        "\n",
        "tsne = TSNE(n_components=2,learning_rate='auto',init='pca',perplexity=30).fit_transform(features) #,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyRPkjPyxrLX"
      },
      "outputs": [],
      "source": [
        "colors = np.array([\"red\",\"green\",\"blue\",\"yellow\",\"pink\",\"black\",\"orange\",\"purple\",\"beige\",\"brown\"])\n",
        "c = np.array([colors[el] for el in labels])\n",
        "tsne_sel = tsne#[(labels==1)|(labels==4)]\n",
        "#col_sel = c#[(labels==3)|(labels==5)]\n",
        "#plt.scatter(tsne_sel[:,0], tsne_sel[:,1], c=col_sel)\n",
        "plt.scatter(tsne_sel[:,0], tsne_sel[:,1]) #,c=col_sel)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a25effbdb37c891a2e9d4084264472a304386d1b4f4a3dd9d5e57807f471f70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
