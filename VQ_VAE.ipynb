{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import itertools\n",
        "import gc\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omv8PhrnmPmG"
      },
      "outputs": [],
      "source": [
        "class VectorQuantizerEMA(torch.nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
        "        super(VectorQuantizerEMA, self).__init__()\n",
        "        \n",
        "        self._embedding_dim = embedding_dim\n",
        "        self._num_embeddings = num_embeddings\n",
        "        \n",
        "        self._embedding = torch.nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
        "        self._embedding.weight.data.normal_()\n",
        "        self._commitment_cost = commitment_cost\n",
        "        \n",
        "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
        "        self._ema_w = torch.nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
        "        self._ema_w.data.normal_()\n",
        "        \n",
        "        self._decay = decay\n",
        "        self._epsilon = epsilon\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # convert inputs from BCHW -> BHWC\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        input_shape = inputs.shape\n",
        "        \n",
        "        # Flatten input\n",
        "        flat_input = inputs.view(-1, self._embedding_dim)\n",
        "        \n",
        "        # Calculate distances\n",
        "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
        "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
        "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
        "            \n",
        "        # Encoding\n",
        "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
        "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
        "        encodings.scatter_(1, encoding_indices, 1)\n",
        "        \n",
        "        # Quantize and unflatten\n",
        "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
        "        \n",
        "        # Use EMA to update the embedding vectors\n",
        "        if self.training:\n",
        "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
        "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
        "            \n",
        "            # Laplace smoothing of the cluster size\n",
        "            n = torch.sum(self._ema_cluster_size.data)\n",
        "            self._ema_cluster_size = (\n",
        "                (self._ema_cluster_size + self._epsilon)\n",
        "                / (n + self._num_embeddings * self._epsilon) * n)\n",
        "            \n",
        "            dw = torch.matmul(encodings.t(), flat_input)\n",
        "            self._ema_w = torch.nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
        "            \n",
        "            self._embedding.weight = torch.nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
        "        \n",
        "        # Loss\n",
        "        e_latent_loss = torch.nn.functional.mse_loss(quantized.detach(), inputs)\n",
        "        loss = self._commitment_cost * e_latent_loss\n",
        "        \n",
        "        # Straight Through Estimator\n",
        "        quantized = inputs + (quantized - inputs).detach()\n",
        "        avg_probs = torch.mean(encodings, dim=0)\n",
        "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
        "        \n",
        "        # convert quantized from BHWC -> BCHW\n",
        "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQsosddb1NyX"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim):\n",
        "    super().__init__()\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(n_input_channels, hidden_size, kernel_size=3, stride=2, padding=1),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, hidden_size, kernel_size=3),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, 2*hidden_size, kernel_size=3),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(2*hidden_size, 2*hidden_size, kernel_size=3, stride=2),\n",
        "        torch.nn.GELU(),\n",
        "        #torch.nn.Flatten()\n",
        "    )\n",
        "\n",
        "    #self.linear_mean = torch.nn.Linear(2*hidden_size*25, latent_dim)\n",
        "    #self.linear_logvar = torch.nn.Linear(2*hidden_size*25, latent_dim)\n",
        "    #self.linear = torch.nn.Linear(2*hidden_size*16, latent_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    #x = self.linear(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEJJPsXK6UbO"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim):\n",
        "    super().__init__()\n",
        "    #self.linear = torch.nn.Sequential(torch.nn.Linear(latent_dim, 2 * 16 * hidden_size), torch.nn.GELU())\n",
        "\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.ConvTranspose2d(2*hidden_size, 2*hidden_size, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(2*hidden_size, 2*hidden_size, kernel_size=3, padding=1),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.ConvTranspose2d(2*hidden_size, hidden_size, kernel_size=3, stride=2, output_padding=1, padding=1), \n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Conv2d(hidden_size, hidden_size, kernel_size=3), # , padding=1\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.ConvTranspose2d(hidden_size, n_input_channels, kernel_size=3, stride=2, output_padding=1, padding=1), \n",
        "        torch.nn.Tanh(),\n",
        "        #torch.nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    #x = self.linear(x)\n",
        "    #x = x.reshape(x.shape[0], -1, 4, 4)\n",
        "    x = self.model(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiaPnvn9A_jZ"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(torch.nn.Module):\n",
        "  def __init__(self, n_input_channels, hidden_size, latent_dim, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(n_input_channels, hidden_size, latent_dim)\n",
        "    self.decoder = Decoder(n_input_channels, hidden_size, latent_dim)\n",
        "    self._vq_vae = VectorQuantizerEMA(num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    loss, quantized, perplexity, enc = self._vq_vae(x)\n",
        "    x = self.decoder(quantized)\n",
        "    return x, enc, loss, perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Xxbj7UGFQC"
      },
      "outputs": [],
      "source": [
        "def visualize_grid(x_batch):\n",
        "  im_rec = Image.fromarray(torchvision.utils.make_grid((x_batch*0.5+0.5) * 255).permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "  #im_rec = Image.fromarray(torchvision.utils.make_grid((x_batch) * 255).permute(1, 2, 0).cpu().numpy().astype(np.uint8))\n",
        "  return im_rec.resize((im_rec.size[0]*4, im_rec.size[1]*4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jSbPO8E04on",
        "outputId": "3d11bae4-93e4-413b-f85a-bebe6d77f78b"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))\n",
        "     ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkU_V8b2BpRB"
      },
      "outputs": [],
      "source": [
        "if trainset.data.shape[-1] == 3: \n",
        "    n_input_channels, hidden_size, latent_dim = 3, 28, 24\n",
        "else:\n",
        "    n_input_channels, hidden_size, latent_dim = 1, 28, 24\n",
        "    \n",
        "num_embeddings, embedding_dim, commitment_cost = 128, 56, 0.25 # embedding_dim = num_channels at the output of the encoder\n",
        "learning_rate = 1e-3\n",
        "decay = 0.99\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Autoencoder(n_input_channels, hidden_size, latent_dim, num_embeddings, embedding_dim, commitment_cost, decay).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "trials = {}\n",
        "for num_embeddings in range(5, 350, 5): \n",
        "    for embedding_dem in range(5, 350, 5): \n",
        "        trials[num_embeddings,embedding_dim] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6sq3KSsqjhU"
      },
      "outputs": [],
      "source": [
        "if type(trainset.data) is np.ndarray:\n",
        "    data_variance = np.var(trainset.data / 255.0)\n",
        "else:\n",
        "    data_variance = torch.var(trainset.data / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22QYoamrC28c",
        "outputId": "2ff9519b-e251-47d3-a075-efa1db489a25"
      },
      "outputs": [],
      "source": [
        "for epoch in range(7):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        x, labels = data\n",
        "        x = x.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #x, enc, loss, perplexity\n",
        "        x_hat, enc, vq_loss, perplexity = model(x)\n",
        "        mse_loss = torch.nn.functional.mse_loss(x, x_hat) / data_variance\n",
        "        #mse_loss = mse_loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
        "        #bce_loss = torch.nn.functional.binary_cross_entropy(x_hat.view(-1, 1024), x.view(-1, 1024), reduction='sum')\n",
        "        #loss = bce_loss + kl_loss \n",
        "        loss = mse_loss + vq_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % batch_size * 5 == batch_size * 5 - 5:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (batch_size * 5):.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    if (epoch + 1) % 3 == 0:\n",
        "      for g in optimizer.param_groups:\n",
        "        learning_rate *= 0.1\n",
        "        g['lr'] = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for num_embeddings,embedding_dim in trials.keys():\n",
        "#     learning_rate = 1e-3\n",
        "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "#     model = Autoencoder(n_input_channels, hidden_size, latent_dim, num_embeddings, embedding_dim, commitment_cost).to(device)\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "#     for epoch in range(7):\n",
        "#         running_loss = 0.0\n",
        "#         for i, data in enumerate(trainloader, 0):\n",
        "#             x, labels = data\n",
        "#             x = x.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             #x, enc, loss, perplexity\n",
        "#             x_hat, enc, vq_loss, perplexity = model(x)\n",
        "#             mse_loss = torch.nn.functional.mse_loss(x, x_hat) / data_variance\n",
        "#             #mse_loss = mse_loss.sum(dim=[1, 2, 3]).mean(dim=[0])\n",
        "#             #bce_loss = torch.nn.functional.binary_cross_entropy(x_hat.view(-1, 1024), x.view(-1, 1024), reduction='sum')\n",
        "#             #loss = bce_loss + kl_loss \n",
        "#             loss = mse_loss + vq_loss\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             running_loss += loss.item()\n",
        "#             if i % batch_size * 5 == batch_size * 5 - 5:\n",
        "#                 print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (batch_size * 5):.3f}')\n",
        "#                 running_loss = 0.0\n",
        "\n",
        "#         if (epoch + 1) % 3 == 0:\n",
        "#             for g in optimizer.param_groups:\n",
        "#                 learning_rate *= 0.1\n",
        "#                 g['lr'] = learning_rate\n",
        "                \n",
        "#     trials[num_embeddings,embedding_dim].append(running_loss / (batch_size * 5))\n",
        "#     gc.collect()\n",
        "# with open('tune_hyperperameters.pkl', 'bw') as f:\n",
        "#         pickle.dump(trials, f)\n",
        "# print(trials)\n",
        "\n",
        "# with open('tune_hyperperameters.txt', 'w') as f:\n",
        "#     for key, value in trials.items():\n",
        "#         f.write(f'num_embeddings:{key[0]} - embedding_dim:{key[1]} - loss:{value}\\n')\n",
        "\n",
        "trials.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxU0kJxyFemS"
      },
      "outputs": [],
      "source": [
        "for data in testloader:\n",
        "  x, labels = data\n",
        "  x = x.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x_hat = model(x)[0]\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bpO7JxA1mDyd",
        "outputId": "f1f01cf9-3b33-4f03-d08b-691d696ce20d"
      },
      "outputs": [],
      "source": [
        "visualize_grid(x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "suxcg6W0H3ul",
        "outputId": "31119e6a-1bde-4774-b932-e5fa955e16a8"
      },
      "outputs": [],
      "source": [
        "visualize_grid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Dk2CiYbhtU_e",
        "outputId": "eb7fa4c3-a610-4b97-d7e2-51cfa9689c70"
      },
      "outputs": [],
      "source": [
        "'''means, lbls = [], []\n",
        "for data in testloader:\n",
        "  x, labels = data\n",
        "  x = x.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x_mean = model.encoder(x)[0]\n",
        "  means.append(x_mean)\n",
        "  lbls.append(labels)\n",
        "\n",
        "features = torch.cat(means,0)\n",
        "features = features.detach().cpu().numpy()\n",
        "labels = torch.cat(lbls).numpy()\n",
        "\n",
        "tsne = TSNE(n_components=2).fit_transform(features)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vyRPkjPyxrLX",
        "outputId": "5dda2625-b74d-4bbb-ebae-1b94aee17843"
      },
      "outputs": [],
      "source": [
        "'''colors = np.array([\"red\",\"green\",\"blue\",\"yellow\",\"pink\",\"black\",\"orange\",\"purple\",\"beige\",\"brown\"])\n",
        "c = np.array([colors[el] for el in labels])\n",
        "tsne_sel = tsne#[(labels==1)|(labels==4)]\n",
        "col_sel = c#[(labels==3)|(labels==5)]\n",
        "plt.scatter(tsne_sel[:,0], tsne_sel[:,1], c=col_sel)'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a25effbdb37c891a2e9d4084264472a304386d1b4f4a3dd9d5e57807f471f70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
