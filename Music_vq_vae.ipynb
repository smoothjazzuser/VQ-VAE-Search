{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oghj-VpeperO"
      },
      "source": [
        "# Before you start\n",
        "Open this link and create a shortcut to indices_genres in your drive: https://drive.google.com/file/d/1-0CjAdc5ZJIw_pxu8ycVBmHnJabAIxEg/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjBkx6Gxpjsh"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIkvQetyvaVU",
        "outputId": "a64e3006-e1bf-4a4f-fb9b-f1a7a903dc32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running colab: False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/home/smoothjazzuser/Desktop/VQ-VAE-Search/'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    colab = True\n",
        "except:\n",
        "    colab = False\n",
        "print (\"Running colab:\", colab)\n",
        "path = \"/content/\" if colab else \"\"\n",
        "#abs path\n",
        "import os\n",
        "path = os.path.abspath(path) + \"/\"\n",
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klCWMwu0VAPR",
        "outputId": "bb582a29-75b5-4840-8e4c-ae8ed07287b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘mel_specs_music’: File exists\n",
            "mkdir: cannot create directory ‘mel_specs_music/train’: File exists\n",
            "mkdir: cannot create directory ‘mel_specs_music/val’: File exists\n",
            "mkdir: cannot create directory ‘mel_specs_music/train/cl’: File exists\n",
            "mkdir: cannot create directory ‘mel_specs_music/val/cl’: File exists\n",
            "fatal: destination path 'VQ-VAE' already exists and is not an empty directory.\n",
            "mv: cannot move './VQ-VAE/' to './VQ_VAE/VQ-VAE': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "!mkdir mel_specs_music\n",
        "!mkdir mel_specs_music/train\n",
        "!mkdir mel_specs_music/val\n",
        "!mkdir mel_specs_music/train/cl\n",
        "!mkdir mel_specs_music/val/cl\n",
        "!git clone https://github.com/nadavbh12/VQ-VAE.git\n",
        "!mv ./VQ-VAE/ ./VQ_VAE/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y-8-_dRak_00"
      },
      "outputs": [],
      "source": [
        "#@title Hyperparams\n",
        "import os\n",
        "bs = 64\n",
        "dict_size = 128\n",
        "epochs = 15\n",
        "\n",
        "h, w = 64, 256 #image size\n",
        "\n",
        "vqvae_music_checkpoints_folder = path + 'vqvae_music_checkpoints/'\n",
        "if not os.path.exists(vqvae_music_checkpoints_folder):\n",
        "    os.mkdir(vqvae_music_checkpoints_folder)\n",
        "\n",
        "ds_dir = path + 'mel_specs_music/val/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFtfCZiZjLD4",
        "outputId": "a752743a-cc12-47d0-ccc4-a5b8b361c0fb"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from VQ_VAE.vq_vae.auto_encoder import VQ_CVAE\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "import librosa\n",
        "import cv2\n",
        "import scipy\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtYE9uvTy_lY",
        "outputId": "e3f6c1f7-2159-4868-8175-56323f4c6f9e"
      },
      "outputs": [],
      "source": [
        "#@title Unzip, filter, undersample, and reorganize data\n",
        "if colab: \n",
        "  !unzip '/content/drive/MyDrive/Big Data Project/large_music_mel_spectrograms.zip'\n",
        "\n",
        "img = glob.glob(path + 'music_mel_spectrograms/*.png')\n",
        "\n",
        "if colab:\n",
        "  with open('/content/drive/MyDrive/indices_genres', 'rb') as f:\n",
        "    ig = pickle.load(f)\n",
        "else:\n",
        "  with open('indices_genres', 'rb') as f:\n",
        "    ig = pickle.load(f)\n",
        "\n",
        "img_ids = list(map(lambda x: os.path.basename(x)[:-4], img))\n",
        "\n",
        "df_filter = pd.DataFrame.from_dict({'genre': [ig[el] for el in img_ids], 'id':img}).dropna()\n",
        "df_filter = pd.concat([df_filter[df_filter['genre'] == genre][:1000].reset_index(drop=True) for genre in list(df_filter['genre'].value_counts()[:-7].keys())]).reset_index(drop=True)\n",
        "img = list(df_filter['id'].values)\n",
        "\n",
        "img_train, img_test = train_test_split(img, test_size=0.2, random_state=42)\n",
        "f_train = lambda x: path + 'mel_specs_music/train/cl/' + os.path.basename(x)\n",
        "f_test = lambda x: path + 'mel_specs_music/val/cl/' + os.path.basename(x)\n",
        "out_train = list(map(f_train, img_train))\n",
        "out_test = list(map(f_test, img_test))\n",
        "\n",
        "import shutil\n",
        "for el1, el2 in zip(img_train, out_train):\n",
        "  shutil.copy(el1, el2)\n",
        "\n",
        "for el1, el2 in zip(img_test, out_test):\n",
        "  shutil.copy(el1, el2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "HjjPXcSGvK35"
      },
      "outputs": [],
      "source": [
        "#@title Tune augmentation hyperparameters\n",
        "size = f'transforms.Resize(({h}, {w}))'\n",
        "replace_main_with = '''dataset_transforms = {\n",
        "    'custom': transforms.Compose([transforms.Grayscale(), transforms.Resize((h, w)), \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5), (0.5))]),\n",
        "    'imagenet': transforms.Compose([transforms.Grayscale(), transforms.Resize((h, w)), \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5), (0.5))]),\n",
        "    'cifar10': transforms.Compose([transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5), (0.5))]),\n",
        "    'mnist': transforms.ToTensor()\n",
        "}'''.replace('transforms.Resize((h, w))', size)\n",
        "replace_main = '''dataset_transforms = {\n",
        "    'custom': transforms.Compose([transforms.Resize(256), transforms.CenterCrop(256),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
        "    'imagenet': transforms.Compose([transforms.Resize(256), transforms.CenterCrop(256),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
        "    'cifar10': transforms.Compose([transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
        "    'mnist': transforms.ToTensor()\n",
        "}'''\n",
        "\n",
        "with open(path + 'VQ_VAE/main.py', 'r') as f:\n",
        "  data = f.read()\n",
        "\n",
        "data = data.replace(replace_main, replace_main_with)\n",
        "\n",
        "with open(path + 'VQ_VAE/main.py', 'w') as f:\n",
        "  f.write(data)\n",
        "\n",
        "\n",
        "replace_main_with = '''dataset_n_channels = {\n",
        "    'custom': 1,\n",
        "    'imagenet': 1,\n",
        "    'cifar10': 1,\n",
        "    'mnist': 1,\n",
        "}'''\n",
        "replace_main = '''dataset_n_channels = {\n",
        "    'custom': 3,\n",
        "    'imagenet': 3,\n",
        "    'cifar10': 3,\n",
        "    'mnist': 1,\n",
        "}'''\n",
        "\n",
        "with open(path + 'VQ_VAE/main.py', 'r') as f:\n",
        "  data = f.read()\n",
        "\n",
        "data = data.replace(replace_main, replace_main_with)\n",
        "\n",
        "with open(path + 'VQ_VAE/main.py', 'w') as f:\n",
        "  f.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "JsihWI-3zFZf"
      },
      "outputs": [],
      "source": [
        "#@title Audio Functions\n",
        "def play_audio(audio_file, sr=22050):\n",
        "    if type(audio_file) == str:\n",
        "        return ipd.Audio(audio_file,  rate=sr)\n",
        "    else:\n",
        "        return ipd.Audio(audio_file, rate=sr)\n",
        "\n",
        "def from_spectrogram(spectrogram,  hop_length=150, n_fft=2000, win=50, sr = 22050):\n",
        "    # undo power_to_db\n",
        "    S = spectrogram\n",
        "    S = librosa.db_to_power(S)\n",
        "    S = librosa.feature.inverse.mel_to_audio(S, sr=sr, n_fft=n_fft, hop_length=hop_length, window=win)\n",
        "    return S\n",
        "\n",
        "def png_to_audio(audio_file='spec.png', n_fft = 2000, hop_length = 150, win = 50, mi = -80.0, m = 0.0, sr = 22050, save=False):\n",
        "    # read image\n",
        "    spec = cv2.imread(audio_file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # de_normalize\n",
        "    spec = (spec * (m - mi) / 255) + mi\n",
        "    spec = spec.astype(np.float32)\n",
        "\n",
        "    # from spectrogram to audio\n",
        "    aud = from_spectrogram(spec, n_fft=n_fft, hop_length=hop_length, win=win, sr=sr)\n",
        "\n",
        "    # save audio\n",
        "    aud = play_audio(aud)\n",
        "    if save:\n",
        "        with open(f'{audio_file[0:-4]}.wav', 'wb') as f:\n",
        "                f.write(aud.data)\n",
        "\n",
        "    return aud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_G_MhSYRurGC",
        "outputId": "7c6f32e0-dee1-4741-f3ac-73c5eb02a8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/smoothjazzuser/Desktop/VQ-VAE-Search/VQ_VAE\n",
            "Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "NumExpr defaulting to 8 threads.\n",
            "Train Epoch: 1 [    0/7232 ( 0%)]   time: 1.64   mse_train: 0.080826 vq_train: 0.001638 commitment_train: 0.001638\n",
            "Train Epoch: 1 [  640/7232 ( 8%)]   time: 0.70   mse_train: 0.445213 vq_train: 0.014806 commitment_train: 0.014806\n",
            "Train Epoch: 1 [ 1280/7232 (17%)]   time: 0.70   mse_train: 0.288412 vq_train: 0.013540 commitment_train: 0.013540\n",
            "Train Epoch: 1 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.218011 vq_train: 0.013013 commitment_train: 0.013013\n",
            "Train Epoch: 1 [ 2560/7232 (35%)]   time: 0.70   mse_train: 0.196570 vq_train: 0.013176 commitment_train: 0.013176\n",
            "Train Epoch: 1 [ 3200/7232 (44%)]   time: 0.70   mse_train: 0.159391 vq_train: 0.013314 commitment_train: 0.013314\n",
            "Train Epoch: 1 [ 3840/7232 (53%)]   time: 0.75   mse_train: 0.119247 vq_train: 0.013376 commitment_train: 0.013376\n",
            "Train Epoch: 1 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.088118 vq_train: 0.013928 commitment_train: 0.013928\n",
            "Train Epoch: 1 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.055168 vq_train: 0.014598 commitment_train: 0.014598\n",
            "Train Epoch: 1 [ 5760/7232 (79%)]   time: 0.76   mse_train: 0.041514 vq_train: 0.015159 commitment_train: 0.015159\n",
            "Train Epoch: 1 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.034212 vq_train: 0.015661 commitment_train: 0.015661\n",
            "Train Epoch: 1 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.029718 vq_train: 0.015742 commitment_train: 0.015742\n",
            "====> Epoch: 1 mse_train: 0.156670\tvq_train: 0.014321\tcommitment_train: 0.014321\n",
            "[  12  278   22  120  122   31  445   52 3316  234   75  499  198  142\n",
            "    2 2742 1025   57   40  543   49 1429  235 2963  314  392  390 1612\n",
            "  116   14  825   99   39  260  421   21  813   25   33  195  158  563\n",
            "  271  298  177  148   18  827  314  136   88 2416  167  270  592   75\n",
            "  369  217  103 2615   62  123   55  325  845  347  442  547]\n",
            "[  0   7   8   9  11  13  16  17  19  22  23  24  25  28  29  30  32  33\n",
            "  34  36  38  40  41  45  46  49  50  52  53  54  58  60  62  63  64  66\n",
            "  68  69  70  71  73  74  75  78  81  86  87  88  90  94  95  98 101 103\n",
            " 105 106 108 110 112 113 114 117 120 121 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.003480 vq_test: 0.002018 commitment_test: 0.002018\n",
            "Train Epoch: 2 [    0/7232 ( 0%)]   time: 0.48   mse_train: 0.002742 vq_train: 0.001557 commitment_train: 0.001557\n",
            "Train Epoch: 2 [  640/7232 ( 8%)]   time: 0.70   mse_train: 0.023881 vq_train: 0.015348 commitment_train: 0.015348\n",
            "Train Epoch: 2 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.021160 vq_train: 0.015363 commitment_train: 0.015363\n",
            "Train Epoch: 2 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.020560 vq_train: 0.015389 commitment_train: 0.015389\n",
            "Train Epoch: 2 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.018381 vq_train: 0.015146 commitment_train: 0.015146\n",
            "Train Epoch: 2 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.018143 vq_train: 0.015159 commitment_train: 0.015159\n",
            "Train Epoch: 2 [ 3840/7232 (53%)]   time: 0.75   mse_train: 0.017610 vq_train: 0.014951 commitment_train: 0.014951\n",
            "Train Epoch: 2 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.016950 vq_train: 0.015038 commitment_train: 0.015038\n",
            "Train Epoch: 2 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.017109 vq_train: 0.014716 commitment_train: 0.014716\n",
            "Train Epoch: 2 [ 5760/7232 (79%)]   time: 0.74   mse_train: 0.015948 vq_train: 0.014672 commitment_train: 0.014672\n",
            "Train Epoch: 2 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.015489 vq_train: 0.014756 commitment_train: 0.014756\n",
            "Train Epoch: 2 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.016011 vq_train: 0.014654 commitment_train: 0.014654\n",
            "====> Epoch: 2 mse_train: 0.018388\tvq_train: 0.015082\tcommitment_train: 0.015082\n",
            "[  69   95  420   62  384  265  195  322   85 2607  442  155  416  186\n",
            "  186  165 2371  665  213  115  405   41  189 1159  332 2157  269  752\n",
            "  287  962  283  151  420  204  208  297  615  206  680  190  165   99\n",
            "  218  954  278  545  150  289   67  481  580  406   77    1 2355  471\n",
            "   26  379  505  263  292  411  125 2046  101  282   92  134  630  299\n",
            "  480  342]\n",
            "[  0   6   7   8   9  11  13  16  17  19  22  23  24  25  28  29  30  32\n",
            "  33  34  36  37  38  40  41  45  46  49  50  52  53  54  58  60  62  63\n",
            "  64  66  68  69  70  71  73  74  75  78  81  86  87  88  90  94  95  97\n",
            "  98 101 102 103 105 106 108 110 112 113 114 117 120 121 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001870 vq_test: 0.001917 commitment_test: 0.001917\n",
            "Train Epoch: 3 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.001334 vq_train: 0.001445 commitment_train: 0.001445\n",
            "Train Epoch: 3 [  640/7232 ( 8%)]   time: 0.75   mse_train: 0.015090 vq_train: 0.014524 commitment_train: 0.014524\n",
            "Train Epoch: 3 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.016236 vq_train: 0.014547 commitment_train: 0.014547\n",
            "Train Epoch: 3 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.014475 vq_train: 0.014319 commitment_train: 0.014319\n",
            "Train Epoch: 3 [ 2560/7232 (35%)]   time: 0.75   mse_train: 0.013588 vq_train: 0.014301 commitment_train: 0.014301\n",
            "Train Epoch: 3 [ 3200/7232 (44%)]   time: 0.70   mse_train: 0.013536 vq_train: 0.014447 commitment_train: 0.014447\n",
            "Train Epoch: 3 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.013373 vq_train: 0.014232 commitment_train: 0.014232\n",
            "Train Epoch: 3 [ 4480/7232 (61%)]   time: 0.75   mse_train: 0.012742 vq_train: 0.014317 commitment_train: 0.014317\n",
            "Train Epoch: 3 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.013170 vq_train: 0.014224 commitment_train: 0.014224\n",
            "Train Epoch: 3 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.012891 vq_train: 0.014185 commitment_train: 0.014185\n",
            "Train Epoch: 3 [ 6400/7232 (88%)]   time: 0.68   mse_train: 0.013164 vq_train: 0.014136 commitment_train: 0.014136\n",
            "Train Epoch: 3 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.013398 vq_train: 0.014092 commitment_train: 0.014092\n",
            "====> Epoch: 3 mse_train: 0.013820\tvq_train: 0.014369\tcommitment_train: 0.014369\n",
            "[ 136  151  359  306  316  340  291  289  135 2259  444  209  397  158\n",
            "  336  244 2117  602  312  265  394   97  368   83  943  385 1453  295\n",
            "  644  376  840  452  152  354  372  420  279  695  190  621  150  152\n",
            "  184  238  655  287  483  215  454  160  445  573  346  137   61 1986\n",
            "  425   72  348  420  243  179  376  204 2310  231  384  171  142  127\n",
            "  490  222  559  260]\n",
            "[  0   6   7   8   9  11  13  16  17  19  22  23  24  25  28  29  30  32\n",
            "  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54  58  60  62\n",
            "  63  64  66  68  69  70  71  73  74  75  78  81  86  87  88  90  94  95\n",
            "  97  98 101 102 103 105 106 108 110 112 113 114 117 120 121 123 124 125\n",
            " 126 127]\n",
            "====> Test set losses: mse_test: 0.001502 vq_test: 0.001854 commitment_test: 0.001854\n",
            "Train Epoch: 4 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.001491 vq_train: 0.001416 commitment_train: 0.001416\n",
            "Train Epoch: 4 [  640/7232 ( 8%)]   time: 0.75   mse_train: 0.013097 vq_train: 0.014194 commitment_train: 0.014194\n",
            "Train Epoch: 4 [ 1280/7232 (17%)]   time: 0.70   mse_train: 0.012440 vq_train: 0.013998 commitment_train: 0.013998\n",
            "Train Epoch: 4 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.011679 vq_train: 0.013969 commitment_train: 0.013969\n",
            "Train Epoch: 4 [ 2560/7232 (35%)]   time: 0.75   mse_train: 0.011834 vq_train: 0.013946 commitment_train: 0.013946\n",
            "Train Epoch: 4 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.011060 vq_train: 0.013958 commitment_train: 0.013958\n",
            "Train Epoch: 4 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.011156 vq_train: 0.014089 commitment_train: 0.014089\n",
            "Train Epoch: 4 [ 4480/7232 (61%)]   time: 0.74   mse_train: 0.011829 vq_train: 0.013972 commitment_train: 0.013972\n",
            "Train Epoch: 4 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.011436 vq_train: 0.013866 commitment_train: 0.013866\n",
            "Train Epoch: 4 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.011471 vq_train: 0.013826 commitment_train: 0.013826\n",
            "Train Epoch: 4 [ 6400/7232 (88%)]   time: 0.75   mse_train: 0.010970 vq_train: 0.013764 commitment_train: 0.013764\n",
            "Train Epoch: 4 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.011494 vq_train: 0.013647 commitment_train: 0.013647\n",
            "====> Epoch: 4 mse_train: 0.011748\tvq_train: 0.013990\tcommitment_train: 0.013990\n",
            "[ 102  226  394  285  406  284  144   84  193  180 1530  277  194  455\n",
            "  193  337  254 1963  795  507  332  329   98  408  258  760  406 1102\n",
            "  270  787  382 1197  452  229  464  376  427  177  542  235  620  122\n",
            "  222  200  256  600  320  815  246    2  203  173  406 1375  362  123\n",
            "  216 1603   85  448  266  432  400  278  371  401  210 1239  296  380\n",
            "  136  188  114  565  191  523  347]\n",
            "[  0   6   7   8   9  11  13  14  16  17  19  22  23  24  25  28  29  30\n",
            "  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54  58  60\n",
            "  62  63  64  66  68  69  70  71  73  74  75  78  81  83  86  87  88  90\n",
            "  94  95  97  98 100 101 102 103 105 106 108 110 112 113 114 117 120 121\n",
            " 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001327 vq_test: 0.001838 commitment_test: 0.001838\n",
            "Train Epoch: 5 [    0/7232 ( 0%)]   time: 0.42   mse_train: 0.001055 vq_train: 0.001350 commitment_train: 0.001350\n",
            "Train Epoch: 5 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.011433 vq_train: 0.013718 commitment_train: 0.013718\n",
            "Train Epoch: 5 [ 1280/7232 (17%)]   time: 0.68   mse_train: 0.011139 vq_train: 0.013623 commitment_train: 0.013623\n",
            "Train Epoch: 5 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.011640 vq_train: 0.013573 commitment_train: 0.013573\n",
            "Train Epoch: 5 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.010691 vq_train: 0.013590 commitment_train: 0.013590\n",
            "Train Epoch: 5 [ 3200/7232 (44%)]   time: 0.75   mse_train: 0.010029 vq_train: 0.013598 commitment_train: 0.013598\n",
            "Train Epoch: 5 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.010446 vq_train: 0.013583 commitment_train: 0.013583\n",
            "Train Epoch: 5 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.010839 vq_train: 0.013505 commitment_train: 0.013505\n",
            "Train Epoch: 5 [ 5120/7232 (70%)]   time: 0.68   mse_train: 0.010940 vq_train: 0.013364 commitment_train: 0.013364\n",
            "Train Epoch: 5 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.011379 vq_train: 0.013426 commitment_train: 0.013426\n",
            "Train Epoch: 5 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.011165 vq_train: 0.013391 commitment_train: 0.013391\n",
            "Train Epoch: 5 [ 7040/7232 (97%)]   time: 0.75   mse_train: 0.010389 vq_train: 0.013424 commitment_train: 0.013424\n",
            "====> Epoch: 5 mse_train: 0.010960\tvq_train: 0.013582\tcommitment_train: 0.013582\n",
            "[ 191  283  475  183  420  270  179  116  194  174 1647  292  161  750\n",
            "  161  325  254 1455  650  435  166  414  125  469  422  766  415 1228\n",
            "  218  923  370 1341  490  324  407  309  438  122  505  151  808  166\n",
            "  305  167  276  477  348  635  148    2   35  222  178  456   17  874\n",
            "    6  371  234  263 1936   86  575  263  376  483  168  257  625  103\n",
            "  934  167   11  541  134   94  100  496  238  556  419]\n",
            "[  0   6   7   8   9  11  13  14  16  17  19  22  23  24  25  28  29  30\n",
            "  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54  58  60\n",
            "  62  63  64  66  68  69  70  71  73  74  75  78  81  82  83  86  87  88\n",
            "  89  90  91  94  95  97  98 100 101 102 103 105 106 108 110 112 113 114\n",
            " 115 117 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001204 vq_test: 0.001734 commitment_test: 0.001734\n",
            "Train Epoch: 6 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.000946 vq_train: 0.001316 commitment_train: 0.001316\n",
            "Train Epoch: 6 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.009403 vq_train: 0.013174 commitment_train: 0.013174\n",
            "Train Epoch: 6 [ 1280/7232 (17%)]   time: 0.75   mse_train: 0.010975 vq_train: 0.013126 commitment_train: 0.013126\n",
            "Train Epoch: 6 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.009397 vq_train: 0.013063 commitment_train: 0.013063\n",
            "Train Epoch: 6 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.010314 vq_train: 0.013197 commitment_train: 0.013197\n",
            "Train Epoch: 6 [ 3200/7232 (44%)]   time: 0.75   mse_train: 0.009530 vq_train: 0.013142 commitment_train: 0.013142\n",
            "Train Epoch: 6 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.009840 vq_train: 0.013054 commitment_train: 0.013054\n",
            "Train Epoch: 6 [ 4480/7232 (61%)]   time: 0.70   mse_train: 0.009957 vq_train: 0.013073 commitment_train: 0.013073\n",
            "Train Epoch: 6 [ 5120/7232 (70%)]   time: 0.75   mse_train: 0.009282 vq_train: 0.013076 commitment_train: 0.013076\n",
            "Train Epoch: 6 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.010013 vq_train: 0.013111 commitment_train: 0.013111\n",
            "Train Epoch: 6 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.009591 vq_train: 0.012919 commitment_train: 0.012919\n",
            "Train Epoch: 6 [ 7040/7232 (97%)]   time: 0.68   mse_train: 0.009869 vq_train: 0.012957 commitment_train: 0.012957\n",
            "====> Epoch: 6 mse_train: 0.009869\tvq_train: 0.013134\tcommitment_train: 0.013134\n",
            "[ 287  275  334  289  399  233  120  165  213  196 2059  207  188  787\n",
            "  121  312  207 1428  816  515  338  340  123  513  613  687  329  959\n",
            "  312  721  474 1352  415  401  383  326  342   92  530  141  755  133\n",
            "  194  163  270  546  344  550  185   47   86  235  155  292   78 1033\n",
            "   26  356  196  261 1843   64  455  376  388  300  149  211  705  134\n",
            " 1149  149   58  539  133  131  166  529  186  433  223]\n",
            "[  0   6   7   8   9  11  13  14  16  17  19  22  23  24  25  28  29  30\n",
            "  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54  58  60\n",
            "  62  63  64  66  68  69  70  71  73  74  75  78  81  82  83  86  87  88\n",
            "  89  90  91  94  95  97  98 100 101 102 103 105 106 108 110 112 113 114\n",
            " 115 117 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001106 vq_test: 0.001718 commitment_test: 0.001718\n",
            "Train Epoch: 7 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.000890 vq_train: 0.001290 commitment_train: 0.001290\n",
            "Train Epoch: 7 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.009787 vq_train: 0.012951 commitment_train: 0.012951\n",
            "Train Epoch: 7 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.008991 vq_train: 0.012885 commitment_train: 0.012885\n",
            "Train Epoch: 7 [ 1920/7232 (26%)]   time: 0.75   mse_train: 0.009544 vq_train: 0.012813 commitment_train: 0.012813\n",
            "Train Epoch: 7 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.009250 vq_train: 0.013015 commitment_train: 0.013015\n",
            "Train Epoch: 7 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.009980 vq_train: 0.012672 commitment_train: 0.012672\n",
            "Train Epoch: 7 [ 3840/7232 (53%)]   time: 0.75   mse_train: 0.009682 vq_train: 0.012676 commitment_train: 0.012676\n",
            "Train Epoch: 7 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.010157 vq_train: 0.012549 commitment_train: 0.012549\n",
            "Train Epoch: 7 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.009348 vq_train: 0.012783 commitment_train: 0.012783\n",
            "Train Epoch: 7 [ 5760/7232 (79%)]   time: 0.75   mse_train: 0.009000 vq_train: 0.012697 commitment_train: 0.012697\n",
            "Train Epoch: 7 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.008953 vq_train: 0.012579 commitment_train: 0.012579\n",
            "Train Epoch: 7 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.009609 vq_train: 0.012459 commitment_train: 0.012459\n",
            "====> Epoch: 7 mse_train: 0.009517\tvq_train: 0.012791\tcommitment_train: 0.012791\n",
            "[ 285  357  182  221  428  308  193  289  222  177 1685  285  194  805\n",
            "  192    3  291  167  886  618  496  293  332  143  465  611  678  377\n",
            "  908  295  465  477 1474  385  415  375  270   50  409  180  440  204\n",
            " 1031   86  167  250  342  534  364  481  264  174  182  294  343  291\n",
            "   72  972   83  350  233  222 1587   62  129  530  630  363  216  204\n",
            "  249  517   95  168 1003  315  154  586  142  179  188  538  114  360\n",
            "  174]\n",
            "[  0   6   7   8   9  11  13  14  16  17  19  22  23  24  25  26  28  29\n",
            "  30  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54  58\n",
            "  60  61  62  63  64  66  68  69  70  71  73  74  75  78  81  82  83  86\n",
            "  87  88  89  90  91  94  95  97  98  99 100 101 102 103 105 106 108 110\n",
            " 111 112 113 114 115 117 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001048 vq_test: 0.001652 commitment_test: 0.001652\n",
            "Train Epoch: 8 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.000799 vq_train: 0.001285 commitment_train: 0.001285\n",
            "Train Epoch: 8 [  640/7232 ( 8%)]   time: 0.68   mse_train: 0.010214 vq_train: 0.012460 commitment_train: 0.012460\n",
            "Train Epoch: 8 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.008838 vq_train: 0.012383 commitment_train: 0.012383\n",
            "Train Epoch: 8 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.008224 vq_train: 0.012857 commitment_train: 0.012857\n",
            "Train Epoch: 8 [ 2560/7232 (35%)]   time: 0.75   mse_train: 0.008784 vq_train: 0.012343 commitment_train: 0.012343\n",
            "Train Epoch: 8 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.008535 vq_train: 0.012445 commitment_train: 0.012445\n",
            "Train Epoch: 8 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.008741 vq_train: 0.012396 commitment_train: 0.012396\n",
            "Train Epoch: 8 [ 4480/7232 (61%)]   time: 0.68   mse_train: 0.010145 vq_train: 0.012348 commitment_train: 0.012348\n",
            "Train Epoch: 8 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.010411 vq_train: 0.012047 commitment_train: 0.012047\n",
            "Train Epoch: 8 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.008667 vq_train: 0.012525 commitment_train: 0.012525\n",
            "Train Epoch: 8 [ 6400/7232 (88%)]   time: 0.68   mse_train: 0.008819 vq_train: 0.011972 commitment_train: 0.011972\n",
            "Train Epoch: 8 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.009455 vq_train: 0.012086 commitment_train: 0.012086\n",
            "====> Epoch: 8 mse_train: 0.009187\tvq_train: 0.012408\tcommitment_train: 0.012408\n",
            "[ 187  425  387  127  480  346  105  429    1  174  126 1316  361  217\n",
            "  765  211  152  291  296  930  529  412  383  622  130  492  460  602\n",
            "  366  933  291  753  521 1193  364  305  545  299  116  420  101  410\n",
            "  128  551  212  315  148  351  416  362  433  230  178  235  186  201\n",
            "  348   83  761  164  330  230  443 1276   73  218  512  376  538  268\n",
            "  202  466  494  173  197  786  161  235    3  694   54  210  163  204\n",
            "  652  170  419  346]\n",
            "[  0   6   7   8   9  11  13  14  15  16  17  19  22  23  24  25  26  28\n",
            "  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53  54\n",
            "  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78  81  82  83\n",
            "  86  87  88  89  90  91  94  95  97  98  99 100 101 102 103 105 106 108\n",
            " 110 111 112 113 114 115 116 117 119 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.001008 vq_test: 0.001610 commitment_test: 0.001610\n",
            "Train Epoch: 9 [    0/7232 ( 0%)]   time: 0.45   mse_train: 0.000871 vq_train: 0.001227 commitment_train: 0.001227\n",
            "Train Epoch: 9 [  640/7232 ( 8%)]   time: 0.68   mse_train: 0.009033 vq_train: 0.011949 commitment_train: 0.011949\n",
            "Train Epoch: 9 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.008674 vq_train: 0.012049 commitment_train: 0.012049\n",
            "Train Epoch: 9 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.008397 vq_train: 0.012368 commitment_train: 0.012368\n",
            "Train Epoch: 9 [ 2560/7232 (35%)]   time: 0.68   mse_train: 0.008263 vq_train: 0.012206 commitment_train: 0.012206\n",
            "Train Epoch: 9 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.007842 vq_train: 0.011969 commitment_train: 0.011969\n",
            "Train Epoch: 9 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.008176 vq_train: 0.011894 commitment_train: 0.011894\n",
            "Train Epoch: 9 [ 4480/7232 (61%)]   time: 0.75   mse_train: 0.007850 vq_train: 0.012023 commitment_train: 0.012023\n",
            "Train Epoch: 9 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.008361 vq_train: 0.011939 commitment_train: 0.011939\n",
            "Train Epoch: 9 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.008744 vq_train: 0.011674 commitment_train: 0.011674\n",
            "Train Epoch: 9 [ 6400/7232 (88%)]   time: 0.75   mse_train: 0.007614 vq_train: 0.011815 commitment_train: 0.011815\n",
            "Train Epoch: 9 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.007925 vq_train: 0.011661 commitment_train: 0.011661\n",
            "====> Epoch: 9 mse_train: 0.008295\tvq_train: 0.012011\tcommitment_train: 0.012011\n",
            "[ 260  266  322  100  398  250  215  358   17  187  140 1497   55  321\n",
            "  130  951  253  322  228  205 1251  639  507  429  451  200  373  457\n",
            "  583  363  808  439  555  476  793  206  382  326  309  181  316   83\n",
            "  380  163  827  122  184  151  350  431  374  525  495  176  215  112\n",
            "  163  225  169  836  170  292  209  251 1033  343  261  538  645  595\n",
            "  177  207  332  767  209  211  957  218  227   31  518  139  182  181\n",
            "  210  799  145  297  124]\n",
            "[  0   6   7   8   9  11  13  14  15  16  17  19  21  22  23  24  25  26\n",
            "  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50  52  53\n",
            "  54  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78  81  82\n",
            "  83  86  87  88  89  90  91  94  95  97  98  99 100 101 102 103 105 106\n",
            " 108 110 111 112 113 114 115 116 117 119 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.000925 vq_test: 0.001559 commitment_test: 0.001559\n",
            "Train Epoch: 10 [    0/7232 ( 0%)]   time: 0.42   mse_train: 0.001188 vq_train: 0.001205 commitment_train: 0.001205\n",
            "Train Epoch: 10 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.008112 vq_train: 0.011677 commitment_train: 0.011677\n",
            "Train Epoch: 10 [ 1280/7232 (17%)]   time: 0.68   mse_train: 0.008027 vq_train: 0.011654 commitment_train: 0.011654\n",
            "Train Epoch: 10 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.008230 vq_train: 0.011992 commitment_train: 0.011992\n",
            "Train Epoch: 10 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.008424 vq_train: 0.011633 commitment_train: 0.011633\n",
            "Train Epoch: 10 [ 3200/7232 (44%)]   time: 0.68   mse_train: 0.007609 vq_train: 0.011656 commitment_train: 0.011656\n",
            "Train Epoch: 10 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.007585 vq_train: 0.011680 commitment_train: 0.011680\n",
            "Train Epoch: 10 [ 4480/7232 (61%)]   time: 0.70   mse_train: 0.007990 vq_train: 0.011499 commitment_train: 0.011499\n",
            "Train Epoch: 10 [ 5120/7232 (70%)]   time: 0.68   mse_train: 0.007625 vq_train: 0.011440 commitment_train: 0.011440\n",
            "Train Epoch: 10 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.008112 vq_train: 0.011573 commitment_train: 0.011573\n",
            "Train Epoch: 10 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.008071 vq_train: 0.011604 commitment_train: 0.011604\n",
            "Train Epoch: 10 [ 7040/7232 (97%)]   time: 0.68   mse_train: 0.007729 vq_train: 0.011377 commitment_train: 0.011377\n",
            "====> Epoch: 10 mse_train: 0.008037\tvq_train: 0.011670\tcommitment_train: 0.011670\n",
            "[ 261   43  418  196  197  290  396  239  511  142  170   75 1959  369\n",
            "  176  203  762  299  196  242  142 1027  433  454  374  226  152  532\n",
            "  534  752  429  441  491  517  470 1248  233  346  162  338  191  345\n",
            "  148  371  149  659   49  126  160  449  563  314  317  302  221   90\n",
            "  224  198  210  117  606   99  257  289  137 1203  323  258  499  803\n",
            "  614   96  201  182  554  282  236  961  370  223   32  621  361  172\n",
            "  171  276  734  195  287   78]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  19  21  22  23  24  25\n",
            "  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50  52\n",
            "  53  54  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78  81\n",
            "  82  83  86  87  88  89  90  91  94  95  97  98  99 100 101 102 103 105\n",
            " 106 108 110 111 112 113 114 115 116 117 119 120 121 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.000919 vq_test: 0.001503 commitment_test: 0.001503\n",
            "Train Epoch: 11 [    0/7232 ( 0%)]   time: 0.44   mse_train: 0.000939 vq_train: 0.001134 commitment_train: 0.001134\n",
            "Train Epoch: 11 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.007961 vq_train: 0.011693 commitment_train: 0.011693\n",
            "Train Epoch: 11 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.007730 vq_train: 0.011330 commitment_train: 0.011330\n",
            "Train Epoch: 11 [ 1920/7232 (26%)]   time: 0.75   mse_train: 0.007816 vq_train: 0.011667 commitment_train: 0.011667\n",
            "Train Epoch: 11 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.007764 vq_train: 0.011329 commitment_train: 0.011329\n",
            "Train Epoch: 11 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.007568 vq_train: 0.011174 commitment_train: 0.011174\n",
            "Train Epoch: 11 [ 3840/7232 (53%)]   time: 0.75   mse_train: 0.008662 vq_train: 0.011392 commitment_train: 0.011392\n",
            "Train Epoch: 11 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.007645 vq_train: 0.011237 commitment_train: 0.011237\n",
            "Train Epoch: 11 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.007778 vq_train: 0.011313 commitment_train: 0.011313\n",
            "Train Epoch: 11 [ 5760/7232 (79%)]   time: 0.75   mse_train: 0.007778 vq_train: 0.011314 commitment_train: 0.011314\n",
            "Train Epoch: 11 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.007243 vq_train: 0.011244 commitment_train: 0.011244\n",
            "Train Epoch: 11 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.007197 vq_train: 0.011184 commitment_train: 0.011184\n",
            "====> Epoch: 11 mse_train: 0.007813\tvq_train: 0.011403\tcommitment_train: 0.011403\n",
            "[ 252  281  362  244  155  416  351  242  455  201  191  135    8 1077\n",
            "  362  211   90  933  220  285  250  192 1020  549  432  386  379  230\n",
            "  502  394  717  252  434  370  463  560 1230  247  410  256  291  145\n",
            "  322  138  447  104  533  146  186  133  441  506  370  399  376  226\n",
            "  184  121  147  245  137  743  234  340  206  222 1124  414  343  540\n",
            "  790  522  141  248  257  539  288  169  787  421  205  164  458  215\n",
            "  190  229  170  818  121  369  160]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  18  19  21  22  23  24\n",
            "  25  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50\n",
            "  52  53  54  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78\n",
            "  81  82  83  86  87  88  89  90  91  94  95  97  98  99 100 101 102 103\n",
            " 105 106 108 110 111 112 113 114 115 116 117 119 120 121 123 124 125 126\n",
            " 127]\n",
            "====> Test set losses: mse_test: 0.000875 vq_test: 0.001478 commitment_test: 0.001478\n",
            "Train Epoch: 12 [    0/7232 ( 0%)]   time: 0.44   mse_train: 0.000898 vq_train: 0.001144 commitment_train: 0.001144\n",
            "Train Epoch: 12 [  640/7232 ( 8%)]   time: 0.68   mse_train: 0.007817 vq_train: 0.011187 commitment_train: 0.011187\n",
            "Train Epoch: 12 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.007896 vq_train: 0.011271 commitment_train: 0.011271\n",
            "Train Epoch: 12 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.007328 vq_train: 0.010987 commitment_train: 0.010987\n",
            "Train Epoch: 12 [ 2560/7232 (35%)]   time: 0.75   mse_train: 0.007751 vq_train: 0.011206 commitment_train: 0.011206\n",
            "Train Epoch: 12 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.007931 vq_train: 0.011000 commitment_train: 0.011000\n",
            "Train Epoch: 12 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.009057 vq_train: 0.011149 commitment_train: 0.011149\n",
            "Train Epoch: 12 [ 4480/7232 (61%)]   time: 0.75   mse_train: 0.007997 vq_train: 0.011092 commitment_train: 0.011092\n",
            "Train Epoch: 12 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.007935 vq_train: 0.011391 commitment_train: 0.011391\n",
            "Train Epoch: 12 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.007499 vq_train: 0.010775 commitment_train: 0.010775\n",
            "Train Epoch: 12 [ 6400/7232 (88%)]   time: 0.68   mse_train: 0.007892 vq_train: 0.011436 commitment_train: 0.011436\n",
            "Train Epoch: 12 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.007318 vq_train: 0.010952 commitment_train: 0.010952\n",
            "====> Epoch: 12 mse_train: 0.007879\tvq_train: 0.011180\tcommitment_train: 0.011180\n",
            "[ 279  130  381  268  156  340  251  218  673  217  222   87  180 1399\n",
            "  321  242  144  771  340  277  213  216  774  512  487  400  296  176\n",
            "  452  428  743  340  445  432  514  537 1086  246  352  206  338  131\n",
            "  264  129  402   75  630  155  187  148  419  481  382  320  342  228\n",
            "  132  151  164  208  142  711  154  292  201  101  214 1244  354  338\n",
            "  583  754  545  179  167  275  571  326  214  900  432  288   85  584\n",
            "  244  181  145  171  691  128  348  169]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  18  19  21  22  23  24\n",
            "  25  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50\n",
            "  52  53  54  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78\n",
            "  81  82  83  86  87  88  89  90  91  94  95  96  97  98  99 100 101 102\n",
            " 103 105 106 108 110 111 112 113 114 115 116 117 119 120 121 123 124 125\n",
            " 126 127]\n",
            "====> Test set losses: mse_test: 0.000846 vq_test: 0.001458 commitment_test: 0.001458\n",
            "Train Epoch: 13 [    0/7232 ( 0%)]   time: 0.43   mse_train: 0.000670 vq_train: 0.001115 commitment_train: 0.001115\n",
            "Train Epoch: 13 [  640/7232 ( 8%)]   time: 0.68   mse_train: 0.008207 vq_train: 0.011146 commitment_train: 0.011146\n",
            "Train Epoch: 13 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.007541 vq_train: 0.010975 commitment_train: 0.010975\n",
            "Train Epoch: 13 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.007614 vq_train: 0.011175 commitment_train: 0.011175\n",
            "Train Epoch: 13 [ 2560/7232 (35%)]   time: 0.75   mse_train: 0.007664 vq_train: 0.010926 commitment_train: 0.010926\n",
            "Train Epoch: 13 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.007563 vq_train: 0.010775 commitment_train: 0.010775\n",
            "Train Epoch: 13 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.008019 vq_train: 0.011035 commitment_train: 0.011035\n",
            "Train Epoch: 13 [ 4480/7232 (61%)]   time: 0.75   mse_train: 0.007503 vq_train: 0.010905 commitment_train: 0.010905\n",
            "Train Epoch: 13 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.006736 vq_train: 0.010732 commitment_train: 0.010732\n",
            "Train Epoch: 13 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.007043 vq_train: 0.010773 commitment_train: 0.010773\n",
            "Train Epoch: 13 [ 6400/7232 (88%)]   time: 0.75   mse_train: 0.006862 vq_train: 0.010980 commitment_train: 0.010980\n",
            "Train Epoch: 13 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.007040 vq_train: 0.010991 commitment_train: 0.010991\n",
            "====> Epoch: 13 mse_train: 0.007453\tvq_train: 0.010999\tcommitment_train: 0.010999\n",
            "[ 204  270  403  331  150  341  242  194  546  249  155   95  282 1280\n",
            "  294  246   77  641  274  268  199  290  623  466  374  274  369  168\n",
            "  488  397  605  358  468  424  422  550 1201  234  392  294  301  153\n",
            "  276  174  426  135  336  159  152  138  456  376  398  377  374  210\n",
            "  246  166  212  231  177  625  493  312  174  213  231 1180  423  338\n",
            "  604  518  647  189  212  244  547  305  161  765  552  270  192  590\n",
            "  266  134  211  166  896  192  358  149]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  18  19  21  22  23  24\n",
            "  25  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50\n",
            "  52  53  54  58  60  61  62  63  64  66  68  69  70  71  73  74  75  78\n",
            "  81  82  83  86  87  88  89  90  91  94  95  96  97  98  99 100 101 102\n",
            " 103 105 106 108 110 111 112 113 114 115 116 117 119 120 121 123 124 125\n",
            " 126 127]\n",
            "====> Test set losses: mse_test: 0.000844 vq_test: 0.001446 commitment_test: 0.001446\n",
            "Train Epoch: 14 [    0/7232 ( 0%)]   time: 0.42   mse_train: 0.000623 vq_train: 0.001087 commitment_train: 0.001087\n",
            "Train Epoch: 14 [  640/7232 ( 8%)]   time: 0.69   mse_train: 0.007344 vq_train: 0.010622 commitment_train: 0.010622\n",
            "Train Epoch: 14 [ 1280/7232 (17%)]   time: 0.75   mse_train: 0.007310 vq_train: 0.011067 commitment_train: 0.011067\n",
            "Train Epoch: 14 [ 1920/7232 (26%)]   time: 0.69   mse_train: 0.007301 vq_train: 0.010764 commitment_train: 0.010764\n",
            "Train Epoch: 14 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.006965 vq_train: 0.010551 commitment_train: 0.010551\n",
            "Train Epoch: 14 [ 3200/7232 (44%)]   time: 0.75   mse_train: 0.006937 vq_train: 0.010780 commitment_train: 0.010780\n",
            "Train Epoch: 14 [ 3840/7232 (53%)]   time: 0.69   mse_train: 0.007843 vq_train: 0.010693 commitment_train: 0.010693\n",
            "Train Epoch: 14 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.007824 vq_train: 0.010717 commitment_train: 0.010717\n",
            "Train Epoch: 14 [ 5120/7232 (70%)]   time: 0.75   mse_train: 0.007598 vq_train: 0.010897 commitment_train: 0.010897\n",
            "Train Epoch: 14 [ 5760/7232 (79%)]   time: 0.69   mse_train: 0.007620 vq_train: 0.010986 commitment_train: 0.010986\n",
            "Train Epoch: 14 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.006790 vq_train: 0.010599 commitment_train: 0.010599\n",
            "Train Epoch: 14 [ 7040/7232 (97%)]   time: 0.75   mse_train: 0.006433 vq_train: 0.010617 commitment_train: 0.010617\n",
            "====> Epoch: 14 mse_train: 0.007300\tvq_train: 0.010809\tcommitment_train: 0.010809\n",
            "[ 244  260  312  217  108  482  161  158  507  325  194   84  287  980\n",
            "  254  175   82  949  314  301  216  207  985  540  531  454  263  210\n",
            "  336  490  680  300  504  401  357  494 1006  196  336    4  154  347\n",
            "  172  215  118  347   84  416  128  140  139  322  420  355  390  441\n",
            "  320  136  127  190  203  123  749  316  281  265  282  179  945  491\n",
            "  441  502  902  705  122  202  195  619  335  184  872  472  260  381\n",
            "  599  275  230  205  156  745  156  325  186]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  18  19  21  22  23  24\n",
            "  25  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  49  50\n",
            "  52  53  54  55  58  60  61  62  63  64  66  68  69  70  71  73  74  75\n",
            "  78  81  82  83  86  87  88  89  90  91  94  95  96  97  98  99 100 101\n",
            " 102 103 105 106 108 110 111 112 113 114 115 116 117 119 120 121 123 124\n",
            " 125 126 127]\n",
            "====> Test set losses: mse_test: 0.000790 vq_test: 0.001421 commitment_test: 0.001421\n",
            "Train Epoch: 15 [    0/7232 ( 0%)]   time: 0.44   mse_train: 0.000617 vq_train: 0.001086 commitment_train: 0.001086\n",
            "Train Epoch: 15 [  640/7232 ( 8%)]   time: 0.70   mse_train: 0.006905 vq_train: 0.010729 commitment_train: 0.010729\n",
            "Train Epoch: 15 [ 1280/7232 (17%)]   time: 0.69   mse_train: 0.007640 vq_train: 0.010793 commitment_train: 0.010793\n",
            "Train Epoch: 15 [ 1920/7232 (26%)]   time: 0.67   mse_train: 0.006873 vq_train: 0.010497 commitment_train: 0.010497\n",
            "Train Epoch: 15 [ 2560/7232 (35%)]   time: 0.69   mse_train: 0.008032 vq_train: 0.010846 commitment_train: 0.010846\n",
            "Train Epoch: 15 [ 3200/7232 (44%)]   time: 0.69   mse_train: 0.007315 vq_train: 0.010626 commitment_train: 0.010626\n",
            "Train Epoch: 15 [ 3840/7232 (53%)]   time: 0.75   mse_train: 0.006916 vq_train: 0.010636 commitment_train: 0.010636\n",
            "Train Epoch: 15 [ 4480/7232 (61%)]   time: 0.69   mse_train: 0.006917 vq_train: 0.010507 commitment_train: 0.010507\n",
            "Train Epoch: 15 [ 5120/7232 (70%)]   time: 0.69   mse_train: 0.007406 vq_train: 0.010554 commitment_train: 0.010554\n",
            "Train Epoch: 15 [ 5760/7232 (79%)]   time: 0.68   mse_train: 0.007298 vq_train: 0.010565 commitment_train: 0.010565\n",
            "Train Epoch: 15 [ 6400/7232 (88%)]   time: 0.69   mse_train: 0.007311 vq_train: 0.010589 commitment_train: 0.010589\n",
            "Train Epoch: 15 [ 7040/7232 (97%)]   time: 0.69   mse_train: 0.007782 vq_train: 0.010659 commitment_train: 0.010659\n",
            "====> Epoch: 15 mse_train: 0.007320\tvq_train: 0.010690\tcommitment_train: 0.010690\n",
            "[ 216  328  337  261  137  385  179  167  385  221  215   81  334 1583\n",
            "  346  315  157  580  257  155  148  259  677  473  405  418  321  162\n",
            "  290  442  503  286  502  492   93  409  460   34 1405  334  342   58\n",
            "  201  307  142  182  114  292   93  474  120  149   89  254  403  264\n",
            "  266  376  186  202  169  185  176  133  624  791  225  130  368  214\n",
            " 1036  487  442  411  708  889  187  146  142  741  253  224  770  442\n",
            "  235  409  662  248  146  168  150 1060  131  259  141]\n",
            "[  0   4   6   7   8   9  11  13  14  15  16  17  18  19  21  22  23  24\n",
            "  25  26  28  29  30  32  33  34  36  37  38  39  40  41  45  46  48  49\n",
            "  50  51  52  53  54  55  58  60  61  62  63  64  66  68  69  70  71  73\n",
            "  74  75  78  81  82  83  86  87  88  89  90  91  94  95  96  97  98  99\n",
            " 100 101 102 103 105 106 108 110 111 112 113 114 115 116 117 119 120 121\n",
            " 123 124 125 126 127]\n",
            "====> Test set losses: mse_test: 0.000819 vq_test: 0.001418 commitment_test: 0.001418\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/home/smoothjazzuser/Desktop/VQ-VAE-Search/vqvae_music_checkpoints/model_9.pth'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Train and save to drive (be sure to save the previous trained model somewhere else as the checkpoint folder will be emptied)\n",
        "VQVAE_path = path + 'VQ_VAE'\n",
        "%cd $VQVAE_path\n",
        "if colab:\n",
        "    !python3 main.py --dataset=custom --model=vqvae --data-dir=/content/mel_specs_music --epochs={epochs} --batch-size {bs} --dict-size {dict_size}\n",
        "    checkpoint_path = sorted(glob.glob('/content/VQ_VAE/results/*/checkpoints/*.pth'))[-1]\n",
        "else:\n",
        "    !python3 main.py --dataset=custom --model=vqvae --data-dir=../mel_specs_music --epochs={epochs} --batch-size {bs} --dict-size {dict_size}\n",
        "    checkpoint_path = sorted(glob.glob('../VQ_VAE/results/*/checkpoints/*.pth'))[-1]\n",
        "\n",
        "!rm -rf {vqvae_music_checkpoints_folder}\n",
        "!mkdir {vqvae_music_checkpoints_folder}\n",
        "\n",
        "shutil.copyfile(checkpoint_path, os.path.join(vqvae_music_checkpoints_folder, os.path.basename(checkpoint_path))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haNJBsw5vapI",
        "outputId": "a917714a-f1f7-4216-aaa9-77b6d4569a0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Load model\n",
        "model = VQ_CVAE(128, k=dict_size, num_channels=1) # k has to be equal to dict_size!!!\n",
        "model.load_state_dict(torch.load(checkpoint_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biPBzIUt-jBF",
        "outputId": "9ee954a1-6c51-4c66-a96d-5a3c247c4e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: cd: ~./VQ-VAE-SEARCH: No such file or directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [01:12<00:00,  2.49s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title Predict values\n",
        "if not colab:\n",
        "  !cd ~./VQ-VAE-SEARCH\n",
        "T = transforms.Compose([transforms.Grayscale(), transforms.Resize((h, w)), #transforms.CenterCrop(256),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "test_dataset = torch.utils.data.DataLoader(datasets.ImageFolder(ds_dir, transform=T), batch_size=bs, shuffle=False)\n",
        "\n",
        "categories = []\n",
        "data_names = datasets.ImageFolder(ds_dir, transform=T)\n",
        "data_names = [el[0] for el in data_names.samples]\n",
        "test_ids = list(map(lambda x: os.path.basename(x)[:-4], data_names))\n",
        "categories = [ig[el] for el in test_ids]\n",
        "\n",
        "normalize = lambda x: (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "all_outputs = []\n",
        "i = 0\n",
        "for data, _ in tqdm.tqdm(test_dataset):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(data)[2]\n",
        "    outputs = outputs.reshape(outputs.shape[0], -1).detach().cpu().numpy() #outputs[1] = enc, outputs[2] = emb\n",
        "  all_outputs.append(outputs)\n",
        "  i += 1\n",
        "\n",
        "all_outputs = np.concatenate(all_outputs, 0)\n",
        "#all_outputs = normalize(all_outputs)\n",
        "\n",
        "with open(f'{vqvae_music_checkpoints_folder}/all_outputs.pickle', 'wb') as f:\n",
        "  pickle.dump(all_outputs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gfrnkC6d3y7D"
      },
      "outputs": [],
      "source": [
        "#@title Top K data\n",
        "n_comp = 50\n",
        "with open(f'{vqvae_music_checkpoints_folder}/all_outputs.pickle', 'rb') as f:\n",
        "  all_outputs = pickle.load(f)\n",
        "\n",
        "categories = []\n",
        "data_names = datasets.ImageFolder(ds_dir, transform=T)\n",
        "data_names = [el[0] for el in data_names.samples]\n",
        "test_ids = list(map(lambda x: os.path.basename(x)[:-4], data_names))\n",
        "categories = [ig[el] for el in test_ids]\n",
        "\n",
        "spec_paths = datasets.ImageFolder(ds_dir, transform=T)\n",
        "spec_paths = [el[0] for el in spec_paths.imgs]\n",
        "\n",
        "pca = PCA(n_components=n_comp)\n",
        "pca_result = pca.fit_transform(all_outputs)\n",
        "pca_df = pd.DataFrame(pca_result, columns=list(map(str,list(range(0, n_comp)))))\n",
        "pca_df['categories'] = categories\n",
        "pca_df['spec_paths'] = spec_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "bwjtyW765zFC",
        "outputId": "5f163aac-fded-4f57-fd25-edf728338f30"
      },
      "outputs": [],
      "source": [
        "#@title Top K\n",
        "colab = True\n",
        "#search = audio_search(sr=22050)\n",
        "select_id = 599\n",
        "k = 10\n",
        "vecs = pca_df[list(map(str,list(range(0, n_comp))))].to_numpy()\n",
        "distances = sklearn.metrics.pairwise.cosine_similarity(vecs, vecs)\n",
        "top_k = np.flip(np.argsort(distances[select_id]))[:k]\n",
        "top_k_df = pca_df.iloc[top_k][['categories', 'spec_paths']]\n",
        "audios = [png_to_audio(spec) for spec in top_k_df['spec_paths'].values]\n",
        "display(top_k_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "c2UJDAU9ea5s",
        "outputId": "d60e2a2a-3422-44b5-a348-eb23aee39d23"
      },
      "outputs": [],
      "source": [
        "for audio in audios:\n",
        "  display(audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "rmrdlNZkWbJx",
        "outputId": "6d4e3143-05fd-4bd3-aeda-c9e21ddfc4b8"
      },
      "outputs": [],
      "source": [
        "#@title PCA\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(all_outputs)\n",
        "pca_df = pd.DataFrame(pca_result, columns=['1', '2', '3'])\n",
        "pca_df['categories'] = categories\n",
        "\n",
        "fig = px.scatter_3d(pca_df, x='1', y='2', z='3', color='categories', width=1500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "5LXgjzgtiv03",
        "outputId": "7d7b14f0-8262-4f96-d199-22516361a101"
      },
      "outputs": [],
      "source": [
        "#@title TSNE (requires tuning)\n",
        "\n",
        "pca_tsne = PCA(n_components=50) # change the number of components as a hyperparameter\n",
        "pca_tsne_result = pca_tsne.fit_transform(all_outputs)\n",
        "\n",
        "tsne = TSNE(n_components=3, verbose=1, perplexity=25, n_iter=3000, learning_rate=200)\n",
        "tsne_results = tsne.fit_transform(pca_tsne_result)\n",
        "tsne_df = pd.DataFrame(tsne_results, columns=['1', '2', '3'])\n",
        "tsne_df['categories'] = categories\n",
        "\n",
        "fig = px.scatter_3d(tsne_df, x='1', y='2', z='3', color='categories', width=1200)\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Oghj-VpeperO"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "18f39d5a9bfe4d0ce9b1ccd808a3754df6677d81d118bc81d2886eb8b9b7056c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
